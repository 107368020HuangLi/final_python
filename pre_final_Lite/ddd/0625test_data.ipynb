{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import datasets\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "#from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('0505final_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['HOSDAY'] = train['HOSDAY'].map({\"A\": 0, \"B\":1, \"C\":2, \"D\":3 }).astype(int)\n",
    "#train = shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = train.columns[1:]\n",
    "train_target = train.columns[0]\n",
    "train_feature = train[train_feature]\n",
    "train_y = train[train_target]\n",
    "train_y = train_y.values\n",
    "train_y = np_utils.to_categorical(train_y, num_classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_feature = preprocessing.scale(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( Dense(units=128, input_shape=[52],            #52,47\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer= regularizers.l2(0.1),  #0.04   #0.04   #1å±¤  0.02\n",
    "#           bias_regularizer = regularizers.l2(0.05),  #0.05\n",
    "#           activity_regularizer=regularizers.l2(0.0001),                      \n",
    "                 activation='relu') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.4))  #ep 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( Dense(units=64,\n",
    "                 kernel_initializer='he_normal',  #he_normal\n",
    "                 kernel_regularizer= regularizers.l2(0.1),   #0.06\n",
    "#               bias_regularizer = regularizers.l2(0.05),                \n",
    "#               activity_regularizer=regularizers.l2(0.001),\n",
    "                 activation='relu'))   #relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.4))  #ep 100    #0.5  #0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( Dense(units=4, \n",
    "#                kernel_initializer='normal',\n",
    "                 activation='softmax'))    # kernel_initializer='normal',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer = 'adam' , loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_history = model.fit(new_all_feature , train_y, \n",
    "#                          validation_split=0.1, \n",
    "#                          epochs = 500, batch_size=15,verbose=2)  # 50 ,15  # 100, 15 #500,15  #50,171 #100,171 #500,171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171 samples, validate on 20 samples\n",
      "Epoch 1/500\n",
      "171/171 [==============================] - 0s 1ms/step - loss: 32.1271 - acc: 0.3626 - val_loss: 31.5323 - val_acc: 0.2000\n",
      "Epoch 2/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 31.7249 - acc: 0.3567 - val_loss: 31.2432 - val_acc: 0.2000\n",
      "Epoch 3/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 31.3076 - acc: 0.3743 - val_loss: 30.9139 - val_acc: 0.2000\n",
      "Epoch 4/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 31.0470 - acc: 0.3918 - val_loss: 30.6072 - val_acc: 0.2000\n",
      "Epoch 5/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 30.7712 - acc: 0.4444 - val_loss: 30.2838 - val_acc: 0.2500\n",
      "Epoch 6/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 30.4033 - acc: 0.4094 - val_loss: 29.9728 - val_acc: 0.2500\n",
      "Epoch 7/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 30.1866 - acc: 0.4211 - val_loss: 29.6558 - val_acc: 0.2500\n",
      "Epoch 8/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 29.9199 - acc: 0.4152 - val_loss: 29.3477 - val_acc: 0.2500\n",
      "Epoch 9/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 29.6041 - acc: 0.4211 - val_loss: 29.0378 - val_acc: 0.3000\n",
      "Epoch 10/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 29.1718 - acc: 0.4152 - val_loss: 28.7317 - val_acc: 0.4000\n",
      "Epoch 11/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 28.9727 - acc: 0.3743 - val_loss: 28.4291 - val_acc: 0.4000\n",
      "Epoch 12/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 28.5080 - acc: 0.4269 - val_loss: 28.1294 - val_acc: 0.4000\n",
      "Epoch 13/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 28.2402 - acc: 0.4152 - val_loss: 27.8317 - val_acc: 0.4500\n",
      "Epoch 14/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 27.9174 - acc: 0.4912 - val_loss: 27.5376 - val_acc: 0.4500\n",
      "Epoch 15/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 27.6640 - acc: 0.4620 - val_loss: 27.2476 - val_acc: 0.4500\n",
      "Epoch 16/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 27.3059 - acc: 0.4444 - val_loss: 26.9608 - val_acc: 0.4500\n",
      "Epoch 17/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 26.9940 - acc: 0.4620 - val_loss: 26.6741 - val_acc: 0.4500\n",
      "Epoch 18/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 26.7285 - acc: 0.4854 - val_loss: 26.3938 - val_acc: 0.4500\n",
      "Epoch 19/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 26.4623 - acc: 0.4444 - val_loss: 26.1156 - val_acc: 0.5000\n",
      "Epoch 20/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 26.1785 - acc: 0.4211 - val_loss: 25.8415 - val_acc: 0.5000\n",
      "Epoch 21/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 25.9129 - acc: 0.4678 - val_loss: 25.5702 - val_acc: 0.5000\n",
      "Epoch 22/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 25.6720 - acc: 0.4620 - val_loss: 25.3020 - val_acc: 0.5000\n",
      "Epoch 23/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 25.3200 - acc: 0.4678 - val_loss: 25.0333 - val_acc: 0.5000\n",
      "Epoch 24/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 25.1281 - acc: 0.4386 - val_loss: 24.7705 - val_acc: 0.5000\n",
      "Epoch 25/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 24.8611 - acc: 0.4795 - val_loss: 24.5112 - val_acc: 0.5000\n",
      "Epoch 26/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 24.4409 - acc: 0.4795 - val_loss: 24.2512 - val_acc: 0.5000\n",
      "Epoch 27/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 24.3066 - acc: 0.4561 - val_loss: 23.9972 - val_acc: 0.5000\n",
      "Epoch 28/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 24.0147 - acc: 0.4854 - val_loss: 23.7462 - val_acc: 0.5000\n",
      "Epoch 29/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 23.6883 - acc: 0.4620 - val_loss: 23.4977 - val_acc: 0.5000\n",
      "Epoch 30/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 23.3977 - acc: 0.5205 - val_loss: 23.2521 - val_acc: 0.5000\n",
      "Epoch 31/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 23.2394 - acc: 0.4854 - val_loss: 23.0092 - val_acc: 0.5000\n",
      "Epoch 32/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 23.0455 - acc: 0.4386 - val_loss: 22.7690 - val_acc: 0.5000\n",
      "Epoch 33/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 22.7942 - acc: 0.4795 - val_loss: 22.5309 - val_acc: 0.5000\n",
      "Epoch 34/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 22.4975 - acc: 0.5088 - val_loss: 22.2925 - val_acc: 0.5000\n",
      "Epoch 35/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 22.2324 - acc: 0.5029 - val_loss: 22.0594 - val_acc: 0.5000\n",
      "Epoch 36/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 21.9143 - acc: 0.5731 - val_loss: 21.8291 - val_acc: 0.4500\n",
      "Epoch 37/500\n",
      "171/171 [==============================] - 0s 28us/step - loss: 21.8068 - acc: 0.5146 - val_loss: 21.5991 - val_acc: 0.4500\n",
      "Epoch 38/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 21.5554 - acc: 0.5146 - val_loss: 21.3742 - val_acc: 0.4500\n",
      "Epoch 39/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 21.2843 - acc: 0.5263 - val_loss: 21.1493 - val_acc: 0.4500\n",
      "Epoch 40/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 21.1762 - acc: 0.4912 - val_loss: 20.9291 - val_acc: 0.4500\n",
      "Epoch 41/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 20.9029 - acc: 0.5088 - val_loss: 20.7107 - val_acc: 0.4500\n",
      "Epoch 42/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 20.6086 - acc: 0.5322 - val_loss: 20.4945 - val_acc: 0.4500\n",
      "Epoch 43/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 20.3372 - acc: 0.5205 - val_loss: 20.2808 - val_acc: 0.4500\n",
      "Epoch 44/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 20.2169 - acc: 0.5497 - val_loss: 20.0694 - val_acc: 0.4500\n",
      "Epoch 45/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 19.9923 - acc: 0.5322 - val_loss: 19.8604 - val_acc: 0.4500\n",
      "Epoch 46/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 19.7725 - acc: 0.5556 - val_loss: 19.6518 - val_acc: 0.4500\n",
      "Epoch 47/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 19.6236 - acc: 0.4971 - val_loss: 19.4474 - val_acc: 0.4500\n",
      "Epoch 48/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 19.4164 - acc: 0.4737 - val_loss: 19.2454 - val_acc: 0.4500\n",
      "Epoch 49/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 19.1579 - acc: 0.5439 - val_loss: 19.0456 - val_acc: 0.4500\n",
      "Epoch 50/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 18.9487 - acc: 0.5380 - val_loss: 18.8478 - val_acc: 0.5000\n",
      "Epoch 51/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 18.8079 - acc: 0.5263 - val_loss: 18.6502 - val_acc: 0.5000\n",
      "Epoch 52/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 18.5993 - acc: 0.5789 - val_loss: 18.4549 - val_acc: 0.5000\n",
      "Epoch 53/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 18.3859 - acc: 0.4620 - val_loss: 18.2636 - val_acc: 0.5000\n",
      "Epoch 54/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 18.1315 - acc: 0.5673 - val_loss: 18.0744 - val_acc: 0.5000\n",
      "Epoch 55/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 17.9909 - acc: 0.5497 - val_loss: 17.8876 - val_acc: 0.5000\n",
      "Epoch 56/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 17.8052 - acc: 0.5322 - val_loss: 17.7028 - val_acc: 0.5000\n",
      "Epoch 57/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 17.6060 - acc: 0.5322 - val_loss: 17.5189 - val_acc: 0.5000\n",
      "Epoch 58/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 17.3765 - acc: 0.5380 - val_loss: 17.3384 - val_acc: 0.5000\n",
      "Epoch 59/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 17.2483 - acc: 0.4971 - val_loss: 17.1603 - val_acc: 0.5000\n",
      "Epoch 60/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 17.0833 - acc: 0.5205 - val_loss: 16.9840 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 16.8107 - acc: 0.5322 - val_loss: 16.8097 - val_acc: 0.5000\n",
      "Epoch 62/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 16.6758 - acc: 0.5322 - val_loss: 16.6374 - val_acc: 0.5000\n",
      "Epoch 63/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 16.5311 - acc: 0.4912 - val_loss: 16.4670 - val_acc: 0.5000\n",
      "Epoch 64/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 16.3367 - acc: 0.5731 - val_loss: 16.2983 - val_acc: 0.4500\n",
      "Epoch 65/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 16.2247 - acc: 0.5322 - val_loss: 16.1317 - val_acc: 0.4500\n",
      "Epoch 66/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 15.9630 - acc: 0.5965 - val_loss: 15.9670 - val_acc: 0.4500\n",
      "Epoch 67/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 15.8017 - acc: 0.5556 - val_loss: 15.8042 - val_acc: 0.4500\n",
      "Epoch 68/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 15.7118 - acc: 0.5965 - val_loss: 15.6434 - val_acc: 0.4500\n",
      "Epoch 69/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 15.4782 - acc: 0.5906 - val_loss: 15.4842 - val_acc: 0.4500\n",
      "Epoch 70/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 15.3486 - acc: 0.5380 - val_loss: 15.3266 - val_acc: 0.4500\n",
      "Epoch 71/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 15.1888 - acc: 0.5497 - val_loss: 15.1709 - val_acc: 0.4500\n",
      "Epoch 72/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 15.0260 - acc: 0.5439 - val_loss: 15.0171 - val_acc: 0.5000\n",
      "Epoch 73/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 14.8294 - acc: 0.5848 - val_loss: 14.8650 - val_acc: 0.5000\n",
      "Epoch 74/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 14.7052 - acc: 0.5556 - val_loss: 14.7147 - val_acc: 0.5000\n",
      "Epoch 75/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 14.5603 - acc: 0.5673 - val_loss: 14.5661 - val_acc: 0.5000\n",
      "Epoch 76/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 14.4072 - acc: 0.5263 - val_loss: 14.4189 - val_acc: 0.5000\n",
      "Epoch 77/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 14.2665 - acc: 0.5906 - val_loss: 14.2733 - val_acc: 0.5000\n",
      "Epoch 78/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 14.1494 - acc: 0.5556 - val_loss: 14.1289 - val_acc: 0.5000\n",
      "Epoch 79/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 13.9591 - acc: 0.5673 - val_loss: 13.9861 - val_acc: 0.5000\n",
      "Epoch 80/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 13.8080 - acc: 0.5848 - val_loss: 13.8447 - val_acc: 0.5000\n",
      "Epoch 81/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 13.6704 - acc: 0.5673 - val_loss: 13.7045 - val_acc: 0.5500\n",
      "Epoch 82/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 13.5543 - acc: 0.5848 - val_loss: 13.5662 - val_acc: 0.5500\n",
      "Epoch 83/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 13.4211 - acc: 0.5673 - val_loss: 13.4290 - val_acc: 0.5500\n",
      "Epoch 84/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 13.3171 - acc: 0.5380 - val_loss: 13.2942 - val_acc: 0.5500\n",
      "Epoch 85/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 13.0996 - acc: 0.6316 - val_loss: 13.1610 - val_acc: 0.5500\n",
      "Epoch 86/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 12.9851 - acc: 0.5614 - val_loss: 13.0293 - val_acc: 0.5500\n",
      "Epoch 87/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 12.8760 - acc: 0.6023 - val_loss: 12.8988 - val_acc: 0.5500\n",
      "Epoch 88/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 12.7091 - acc: 0.6199 - val_loss: 12.7691 - val_acc: 0.5500\n",
      "Epoch 89/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 12.5821 - acc: 0.5965 - val_loss: 12.6409 - val_acc: 0.5500\n",
      "Epoch 90/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 12.4861 - acc: 0.5556 - val_loss: 12.5150 - val_acc: 0.5500\n",
      "Epoch 91/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 12.3166 - acc: 0.5906 - val_loss: 12.3906 - val_acc: 0.5500\n",
      "Epoch 92/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 12.2445 - acc: 0.5731 - val_loss: 12.2677 - val_acc: 0.5500\n",
      "Epoch 93/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 12.1007 - acc: 0.6023 - val_loss: 12.1463 - val_acc: 0.5500\n",
      "Epoch 94/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 11.9494 - acc: 0.6316 - val_loss: 12.0260 - val_acc: 0.5500\n",
      "Epoch 95/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 11.8250 - acc: 0.6491 - val_loss: 11.9073 - val_acc: 0.5500\n",
      "Epoch 96/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 11.6767 - acc: 0.6140 - val_loss: 11.7899 - val_acc: 0.5500\n",
      "Epoch 97/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 11.6405 - acc: 0.6082 - val_loss: 11.6739 - val_acc: 0.5500\n",
      "Epoch 98/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 11.5069 - acc: 0.6140 - val_loss: 11.5594 - val_acc: 0.5500\n",
      "Epoch 99/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 11.3843 - acc: 0.6023 - val_loss: 11.4462 - val_acc: 0.5500\n",
      "Epoch 100/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 11.2382 - acc: 0.6374 - val_loss: 11.3345 - val_acc: 0.5500\n",
      "Epoch 101/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 11.1482 - acc: 0.5965 - val_loss: 11.2238 - val_acc: 0.5500\n",
      "Epoch 102/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 11.0569 - acc: 0.5731 - val_loss: 11.1141 - val_acc: 0.5500\n",
      "Epoch 103/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 10.9296 - acc: 0.6023 - val_loss: 11.0055 - val_acc: 0.5500\n",
      "Epoch 104/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 10.8107 - acc: 0.6023 - val_loss: 10.8977 - val_acc: 0.5500\n",
      "Epoch 105/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 10.7296 - acc: 0.5848 - val_loss: 10.7918 - val_acc: 0.5500\n",
      "Epoch 106/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 10.6163 - acc: 0.6082 - val_loss: 10.6870 - val_acc: 0.5500\n",
      "Epoch 107/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 10.5303 - acc: 0.5731 - val_loss: 10.5830 - val_acc: 0.5500\n",
      "Epoch 108/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 10.4272 - acc: 0.6316 - val_loss: 10.4800 - val_acc: 0.5500\n",
      "Epoch 109/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 10.2751 - acc: 0.5731 - val_loss: 10.3789 - val_acc: 0.5500\n",
      "Epoch 110/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 10.1971 - acc: 0.5848 - val_loss: 10.2788 - val_acc: 0.5500\n",
      "Epoch 111/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 10.0559 - acc: 0.6374 - val_loss: 10.1796 - val_acc: 0.5500\n",
      "Epoch 112/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 10.0247 - acc: 0.5789 - val_loss: 10.0818 - val_acc: 0.5500\n",
      "Epoch 113/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 9.8818 - acc: 0.6023 - val_loss: 9.9849 - val_acc: 0.5500\n",
      "Epoch 114/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 9.7523 - acc: 0.5965 - val_loss: 9.8893 - val_acc: 0.5500\n",
      "Epoch 115/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 9.6930 - acc: 0.6199 - val_loss: 9.7948 - val_acc: 0.5500\n",
      "Epoch 116/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 9.5866 - acc: 0.6082 - val_loss: 9.7011 - val_acc: 0.5500\n",
      "Epoch 117/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 9.4978 - acc: 0.6199 - val_loss: 9.6082 - val_acc: 0.5500\n",
      "Epoch 118/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 9.3705 - acc: 0.5965 - val_loss: 9.5167 - val_acc: 0.5500\n",
      "Epoch 119/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 9.3299 - acc: 0.5789 - val_loss: 9.4261 - val_acc: 0.5500\n",
      "Epoch 120/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 9.2379 - acc: 0.5965 - val_loss: 9.3363 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 9.1618 - acc: 0.5614 - val_loss: 9.2475 - val_acc: 0.5500\n",
      "Epoch 122/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 9.0333 - acc: 0.6374 - val_loss: 9.1598 - val_acc: 0.5500\n",
      "Epoch 123/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 8.9516 - acc: 0.5848 - val_loss: 9.0728 - val_acc: 0.5500\n",
      "Epoch 124/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 8.8933 - acc: 0.6199 - val_loss: 8.9869 - val_acc: 0.5500\n",
      "Epoch 125/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 8.7935 - acc: 0.6082 - val_loss: 8.9022 - val_acc: 0.5500\n",
      "Epoch 126/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 8.6840 - acc: 0.5965 - val_loss: 8.8182 - val_acc: 0.5500\n",
      "Epoch 127/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 8.5897 - acc: 0.6316 - val_loss: 8.7356 - val_acc: 0.5500\n",
      "Epoch 128/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 8.5242 - acc: 0.6140 - val_loss: 8.6537 - val_acc: 0.5500\n",
      "Epoch 129/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 8.4654 - acc: 0.5673 - val_loss: 8.5728 - val_acc: 0.5500\n",
      "Epoch 130/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 8.3682 - acc: 0.5906 - val_loss: 8.4925 - val_acc: 0.5500\n",
      "Epoch 131/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 8.2868 - acc: 0.6023 - val_loss: 8.4135 - val_acc: 0.5500\n",
      "Epoch 132/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 8.1574 - acc: 0.6316 - val_loss: 8.3357 - val_acc: 0.5500\n",
      "Epoch 133/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 8.1520 - acc: 0.6199 - val_loss: 8.2584 - val_acc: 0.5500\n",
      "Epoch 134/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 8.0280 - acc: 0.6316 - val_loss: 8.1816 - val_acc: 0.5500\n",
      "Epoch 135/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 7.9804 - acc: 0.6082 - val_loss: 8.1052 - val_acc: 0.5500\n",
      "Epoch 136/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 7.8418 - acc: 0.6199 - val_loss: 8.0294 - val_acc: 0.5500\n",
      "Epoch 137/500\n",
      "171/171 [==============================] - 0s 22us/step - loss: 7.7765 - acc: 0.6082 - val_loss: 7.9550 - val_acc: 0.5500\n",
      "Epoch 138/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 7.7565 - acc: 0.5848 - val_loss: 7.8816 - val_acc: 0.5500\n",
      "Epoch 139/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 7.6577 - acc: 0.6140 - val_loss: 7.8094 - val_acc: 0.5500\n",
      "Epoch 140/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 7.5714 - acc: 0.6140 - val_loss: 7.7379 - val_acc: 0.5500\n",
      "Epoch 141/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 7.5051 - acc: 0.6433 - val_loss: 7.6673 - val_acc: 0.5500\n",
      "Epoch 142/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 7.4185 - acc: 0.6257 - val_loss: 7.5972 - val_acc: 0.5500\n",
      "Epoch 143/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 7.4000 - acc: 0.5848 - val_loss: 7.5277 - val_acc: 0.5500\n",
      "Epoch 144/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 7.3088 - acc: 0.5965 - val_loss: 7.4588 - val_acc: 0.5500\n",
      "Epoch 145/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 7.2558 - acc: 0.6082 - val_loss: 7.3908 - val_acc: 0.5500\n",
      "Epoch 146/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 7.1207 - acc: 0.6374 - val_loss: 7.3235 - val_acc: 0.5500\n",
      "Epoch 147/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 7.1172 - acc: 0.6140 - val_loss: 7.2570 - val_acc: 0.5500\n",
      "Epoch 148/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 7.0590 - acc: 0.5906 - val_loss: 7.1911 - val_acc: 0.5500\n",
      "Epoch 149/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 6.9659 - acc: 0.6199 - val_loss: 7.1263 - val_acc: 0.5500\n",
      "Epoch 150/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.8659 - acc: 0.6316 - val_loss: 7.0621 - val_acc: 0.5500\n",
      "Epoch 151/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.8062 - acc: 0.6433 - val_loss: 6.9988 - val_acc: 0.5500\n",
      "Epoch 152/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.7664 - acc: 0.6023 - val_loss: 6.9361 - val_acc: 0.5500\n",
      "Epoch 153/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 6.7134 - acc: 0.6433 - val_loss: 6.8741 - val_acc: 0.5500\n",
      "Epoch 154/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.6256 - acc: 0.6374 - val_loss: 6.8128 - val_acc: 0.5500\n",
      "Epoch 155/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.5729 - acc: 0.6316 - val_loss: 6.7519 - val_acc: 0.5500\n",
      "Epoch 156/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.5099 - acc: 0.6199 - val_loss: 6.6920 - val_acc: 0.5500\n",
      "Epoch 157/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 6.4521 - acc: 0.6199 - val_loss: 6.6325 - val_acc: 0.5500\n",
      "Epoch 158/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.3833 - acc: 0.6257 - val_loss: 6.5738 - val_acc: 0.5500\n",
      "Epoch 159/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.2947 - acc: 0.6491 - val_loss: 6.5159 - val_acc: 0.5500\n",
      "Epoch 160/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.2827 - acc: 0.6374 - val_loss: 6.4586 - val_acc: 0.5500\n",
      "Epoch 161/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.2167 - acc: 0.6433 - val_loss: 6.4020 - val_acc: 0.5500\n",
      "Epoch 162/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.1757 - acc: 0.6082 - val_loss: 6.3460 - val_acc: 0.5500\n",
      "Epoch 163/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.1260 - acc: 0.6082 - val_loss: 6.2906 - val_acc: 0.5500\n",
      "Epoch 164/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 6.0423 - acc: 0.6140 - val_loss: 6.2356 - val_acc: 0.5500\n",
      "Epoch 165/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.9831 - acc: 0.6433 - val_loss: 6.1812 - val_acc: 0.5500\n",
      "Epoch 166/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 5.9291 - acc: 0.6257 - val_loss: 6.1274 - val_acc: 0.5500\n",
      "Epoch 167/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.8843 - acc: 0.6491 - val_loss: 6.0742 - val_acc: 0.5500\n",
      "Epoch 168/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 5.8450 - acc: 0.6257 - val_loss: 6.0215 - val_acc: 0.5500\n",
      "Epoch 169/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.7607 - acc: 0.6140 - val_loss: 5.9694 - val_acc: 0.5000\n",
      "Epoch 170/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.7089 - acc: 0.6199 - val_loss: 5.9179 - val_acc: 0.5000\n",
      "Epoch 171/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.7019 - acc: 0.6140 - val_loss: 5.8669 - val_acc: 0.5000\n",
      "Epoch 172/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 5.6134 - acc: 0.6199 - val_loss: 5.8167 - val_acc: 0.5000\n",
      "Epoch 173/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 5.5647 - acc: 0.6316 - val_loss: 5.7670 - val_acc: 0.5000\n",
      "Epoch 174/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.5197 - acc: 0.6433 - val_loss: 5.7179 - val_acc: 0.5000\n",
      "Epoch 175/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.4691 - acc: 0.6257 - val_loss: 5.6693 - val_acc: 0.5000\n",
      "Epoch 176/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 5.4082 - acc: 0.6316 - val_loss: 5.6212 - val_acc: 0.5000\n",
      "Epoch 177/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.3829 - acc: 0.6257 - val_loss: 5.5735 - val_acc: 0.5000\n",
      "Epoch 178/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 5.2970 - acc: 0.6140 - val_loss: 5.5262 - val_acc: 0.5000\n",
      "Epoch 179/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.2815 - acc: 0.6257 - val_loss: 5.4794 - val_acc: 0.5000\n",
      "Epoch 180/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.2191 - acc: 0.6257 - val_loss: 5.4332 - val_acc: 0.5500\n",
      "Epoch 181/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 5.1717 - acc: 0.6316 - val_loss: 5.3872 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.1476 - acc: 0.6374 - val_loss: 5.3418 - val_acc: 0.5500\n",
      "Epoch 183/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 5.0793 - acc: 0.6374 - val_loss: 5.2968 - val_acc: 0.5500\n",
      "Epoch 184/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 5.0275 - acc: 0.6491 - val_loss: 5.2525 - val_acc: 0.5500\n",
      "Epoch 185/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.9931 - acc: 0.6082 - val_loss: 5.2089 - val_acc: 0.5500\n",
      "Epoch 186/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 4.9498 - acc: 0.6374 - val_loss: 5.1657 - val_acc: 0.5500\n",
      "Epoch 187/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.9021 - acc: 0.6257 - val_loss: 5.1231 - val_acc: 0.5500\n",
      "Epoch 188/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.8252 - acc: 0.6199 - val_loss: 5.0810 - val_acc: 0.5500\n",
      "Epoch 189/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 4.8113 - acc: 0.6842 - val_loss: 5.0394 - val_acc: 0.5500\n",
      "Epoch 190/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.7838 - acc: 0.6199 - val_loss: 4.9983 - val_acc: 0.5000\n",
      "Epoch 191/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.7512 - acc: 0.6082 - val_loss: 4.9574 - val_acc: 0.5000\n",
      "Epoch 192/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.6960 - acc: 0.6316 - val_loss: 4.9169 - val_acc: 0.5000\n",
      "Epoch 193/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.6569 - acc: 0.6374 - val_loss: 4.8765 - val_acc: 0.5000\n",
      "Epoch 194/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.6072 - acc: 0.6608 - val_loss: 4.8368 - val_acc: 0.5000\n",
      "Epoch 195/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.5691 - acc: 0.6374 - val_loss: 4.7974 - val_acc: 0.5000\n",
      "Epoch 196/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 4.5387 - acc: 0.6667 - val_loss: 4.7586 - val_acc: 0.5000\n",
      "Epoch 197/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.5014 - acc: 0.6550 - val_loss: 4.7205 - val_acc: 0.5000\n",
      "Epoch 198/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 4.4748 - acc: 0.6140 - val_loss: 4.6828 - val_acc: 0.5000\n",
      "Epoch 199/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.4181 - acc: 0.6082 - val_loss: 4.6454 - val_acc: 0.5000\n",
      "Epoch 200/500\n",
      "171/171 [==============================] - 0s 27us/step - loss: 4.3721 - acc: 0.6550 - val_loss: 4.6085 - val_acc: 0.5000\n",
      "Epoch 201/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.3334 - acc: 0.6374 - val_loss: 4.5724 - val_acc: 0.5000\n",
      "Epoch 202/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.2782 - acc: 0.6784 - val_loss: 4.5367 - val_acc: 0.5000\n",
      "Epoch 203/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 4.2710 - acc: 0.6316 - val_loss: 4.5013 - val_acc: 0.5000\n",
      "Epoch 204/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 4.2132 - acc: 0.6667 - val_loss: 4.4664 - val_acc: 0.5000\n",
      "Epoch 205/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 4.2044 - acc: 0.6082 - val_loss: 4.4317 - val_acc: 0.5000\n",
      "Epoch 206/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.1573 - acc: 0.6491 - val_loss: 4.3969 - val_acc: 0.5000\n",
      "Epoch 207/500\n",
      "171/171 [==============================] - 0s 25us/step - loss: 4.0920 - acc: 0.6433 - val_loss: 4.3625 - val_acc: 0.5000\n",
      "Epoch 208/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 4.0760 - acc: 0.6374 - val_loss: 4.3286 - val_acc: 0.5000\n",
      "Epoch 209/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.0537 - acc: 0.6550 - val_loss: 4.2950 - val_acc: 0.5000\n",
      "Epoch 210/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 4.0423 - acc: 0.6316 - val_loss: 4.2615 - val_acc: 0.5000\n",
      "Epoch 211/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.9867 - acc: 0.6433 - val_loss: 4.2287 - val_acc: 0.5000\n",
      "Epoch 212/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.9566 - acc: 0.6316 - val_loss: 4.1960 - val_acc: 0.5000\n",
      "Epoch 213/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 3.8972 - acc: 0.6784 - val_loss: 4.1642 - val_acc: 0.5000\n",
      "Epoch 214/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 3.8990 - acc: 0.6550 - val_loss: 4.1326 - val_acc: 0.5000\n",
      "Epoch 215/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.8300 - acc: 0.6550 - val_loss: 4.1013 - val_acc: 0.5000\n",
      "Epoch 216/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.7901 - acc: 0.6725 - val_loss: 4.0702 - val_acc: 0.5000\n",
      "Epoch 217/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 3.7679 - acc: 0.6550 - val_loss: 4.0396 - val_acc: 0.5000\n",
      "Epoch 218/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.7645 - acc: 0.6316 - val_loss: 4.0095 - val_acc: 0.5000\n",
      "Epoch 219/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.7284 - acc: 0.6491 - val_loss: 3.9796 - val_acc: 0.5000\n",
      "Epoch 220/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.7121 - acc: 0.6374 - val_loss: 3.9500 - val_acc: 0.5000\n",
      "Epoch 221/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.6773 - acc: 0.6608 - val_loss: 3.9205 - val_acc: 0.5000\n",
      "Epoch 222/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.6355 - acc: 0.6491 - val_loss: 3.8912 - val_acc: 0.5000\n",
      "Epoch 223/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 3.5702 - acc: 0.6842 - val_loss: 3.8623 - val_acc: 0.5000\n",
      "Epoch 224/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.5836 - acc: 0.6199 - val_loss: 3.8338 - val_acc: 0.5000\n",
      "Epoch 225/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.5562 - acc: 0.6608 - val_loss: 3.8055 - val_acc: 0.5000\n",
      "Epoch 226/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 3.5165 - acc: 0.6491 - val_loss: 3.7776 - val_acc: 0.5000\n",
      "Epoch 227/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 3.5207 - acc: 0.6257 - val_loss: 3.7499 - val_acc: 0.5000\n",
      "Epoch 228/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.4674 - acc: 0.6257 - val_loss: 3.7225 - val_acc: 0.5000\n",
      "Epoch 229/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.4489 - acc: 0.6901 - val_loss: 3.6952 - val_acc: 0.5000\n",
      "Epoch 230/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.4457 - acc: 0.6140 - val_loss: 3.6682 - val_acc: 0.5000\n",
      "Epoch 231/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 3.3806 - acc: 0.6784 - val_loss: 3.6417 - val_acc: 0.5000\n",
      "Epoch 232/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.3498 - acc: 0.6550 - val_loss: 3.6158 - val_acc: 0.5000\n",
      "Epoch 233/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.3254 - acc: 0.6608 - val_loss: 3.5902 - val_acc: 0.5000\n",
      "Epoch 234/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 3.2746 - acc: 0.6491 - val_loss: 3.5652 - val_acc: 0.5000\n",
      "Epoch 235/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 3.2533 - acc: 0.6667 - val_loss: 3.5403 - val_acc: 0.5000\n",
      "Epoch 236/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 3.2615 - acc: 0.6316 - val_loss: 3.5155 - val_acc: 0.5000\n",
      "Epoch 237/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 3.2073 - acc: 0.6608 - val_loss: 3.4912 - val_acc: 0.5000\n",
      "Epoch 238/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.2024 - acc: 0.6784 - val_loss: 3.4671 - val_acc: 0.5000\n",
      "Epoch 239/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.1766 - acc: 0.6199 - val_loss: 3.4432 - val_acc: 0.5000\n",
      "Epoch 240/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.1470 - acc: 0.6316 - val_loss: 3.4196 - val_acc: 0.5000\n",
      "Epoch 241/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.1193 - acc: 0.6491 - val_loss: 3.3964 - val_acc: 0.5000\n",
      "Epoch 242/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.1062 - acc: 0.6550 - val_loss: 3.3734 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.0490 - acc: 0.6784 - val_loss: 3.3504 - val_acc: 0.5000\n",
      "Epoch 244/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.0479 - acc: 0.6550 - val_loss: 3.3275 - val_acc: 0.5000\n",
      "Epoch 245/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 3.0404 - acc: 0.6667 - val_loss: 3.3049 - val_acc: 0.5000\n",
      "Epoch 246/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 3.0223 - acc: 0.6608 - val_loss: 3.2824 - val_acc: 0.5000\n",
      "Epoch 247/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.9859 - acc: 0.6433 - val_loss: 3.2603 - val_acc: 0.5000\n",
      "Epoch 248/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 2.9790 - acc: 0.6784 - val_loss: 3.2386 - val_acc: 0.5000\n",
      "Epoch 249/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.9479 - acc: 0.6433 - val_loss: 3.2171 - val_acc: 0.5000\n",
      "Epoch 250/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.8991 - acc: 0.6784 - val_loss: 3.1958 - val_acc: 0.5000\n",
      "Epoch 251/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 2.8995 - acc: 0.6491 - val_loss: 3.1745 - val_acc: 0.5000\n",
      "Epoch 252/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.8698 - acc: 0.6608 - val_loss: 3.1536 - val_acc: 0.5000\n",
      "Epoch 253/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.8445 - acc: 0.6667 - val_loss: 3.1328 - val_acc: 0.5000\n",
      "Epoch 254/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 2.8308 - acc: 0.6608 - val_loss: 3.1121 - val_acc: 0.5000\n",
      "Epoch 255/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.8099 - acc: 0.6667 - val_loss: 3.0916 - val_acc: 0.5000\n",
      "Epoch 256/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 2.7914 - acc: 0.6608 - val_loss: 3.0715 - val_acc: 0.5000\n",
      "Epoch 257/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.7680 - acc: 0.6667 - val_loss: 3.0514 - val_acc: 0.5000\n",
      "Epoch 258/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.7614 - acc: 0.6316 - val_loss: 3.0315 - val_acc: 0.5000\n",
      "Epoch 259/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.7365 - acc: 0.6550 - val_loss: 3.0120 - val_acc: 0.5000\n",
      "Epoch 260/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.7028 - acc: 0.6901 - val_loss: 2.9926 - val_acc: 0.5000\n",
      "Epoch 261/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.6681 - acc: 0.6667 - val_loss: 2.9735 - val_acc: 0.5000\n",
      "Epoch 262/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.6669 - acc: 0.6842 - val_loss: 2.9545 - val_acc: 0.5000\n",
      "Epoch 263/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.6348 - acc: 0.6608 - val_loss: 2.9358 - val_acc: 0.5000\n",
      "Epoch 264/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.6267 - acc: 0.6667 - val_loss: 2.9174 - val_acc: 0.5000\n",
      "Epoch 265/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 2.6338 - acc: 0.6491 - val_loss: 2.8991 - val_acc: 0.5000\n",
      "Epoch 266/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.5890 - acc: 0.6842 - val_loss: 2.8812 - val_acc: 0.5000\n",
      "Epoch 267/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.5776 - acc: 0.6901 - val_loss: 2.8637 - val_acc: 0.5000\n",
      "Epoch 268/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.5719 - acc: 0.6316 - val_loss: 2.8463 - val_acc: 0.5000\n",
      "Epoch 269/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.5292 - acc: 0.6374 - val_loss: 2.8291 - val_acc: 0.5000\n",
      "Epoch 270/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 2.5069 - acc: 0.6901 - val_loss: 2.8119 - val_acc: 0.5000\n",
      "Epoch 271/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.5145 - acc: 0.6901 - val_loss: 2.7949 - val_acc: 0.5000\n",
      "Epoch 272/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.4855 - acc: 0.6550 - val_loss: 2.7783 - val_acc: 0.5000\n",
      "Epoch 273/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.4562 - acc: 0.6725 - val_loss: 2.7617 - val_acc: 0.5000\n",
      "Epoch 274/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.4360 - acc: 0.6725 - val_loss: 2.7454 - val_acc: 0.5000\n",
      "Epoch 275/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 2.4280 - acc: 0.6550 - val_loss: 2.7293 - val_acc: 0.5000\n",
      "Epoch 276/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 2.4271 - acc: 0.6608 - val_loss: 2.7132 - val_acc: 0.5000\n",
      "Epoch 277/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 2.3785 - acc: 0.7018 - val_loss: 2.6976 - val_acc: 0.5000\n",
      "Epoch 278/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.3715 - acc: 0.6842 - val_loss: 2.6821 - val_acc: 0.5000\n",
      "Epoch 279/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.3648 - acc: 0.6550 - val_loss: 2.6666 - val_acc: 0.5000\n",
      "Epoch 280/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 2.3415 - acc: 0.6667 - val_loss: 2.6513 - val_acc: 0.5000\n",
      "Epoch 281/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.3379 - acc: 0.6784 - val_loss: 2.6361 - val_acc: 0.5000\n",
      "Epoch 282/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.3390 - acc: 0.6550 - val_loss: 2.6208 - val_acc: 0.5000\n",
      "Epoch 283/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 2.2896 - acc: 0.6959 - val_loss: 2.6057 - val_acc: 0.5500\n",
      "Epoch 284/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.2855 - acc: 0.6725 - val_loss: 2.5911 - val_acc: 0.5500\n",
      "Epoch 285/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.2725 - acc: 0.6842 - val_loss: 2.5767 - val_acc: 0.5500\n",
      "Epoch 286/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.2541 - acc: 0.6784 - val_loss: 2.5626 - val_acc: 0.5500\n",
      "Epoch 287/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 2.2583 - acc: 0.6608 - val_loss: 2.5485 - val_acc: 0.5500\n",
      "Epoch 288/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 2.2124 - acc: 0.6842 - val_loss: 2.5349 - val_acc: 0.5500\n",
      "Epoch 289/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.2317 - acc: 0.6491 - val_loss: 2.5214 - val_acc: 0.5500\n",
      "Epoch 290/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 2.1971 - acc: 0.6667 - val_loss: 2.5079 - val_acc: 0.5500\n",
      "Epoch 291/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.2016 - acc: 0.6725 - val_loss: 2.4941 - val_acc: 0.5500\n",
      "Epoch 292/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.1694 - acc: 0.6901 - val_loss: 2.4802 - val_acc: 0.5500\n",
      "Epoch 293/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.1877 - acc: 0.6667 - val_loss: 2.4666 - val_acc: 0.5500\n",
      "Epoch 294/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.1438 - acc: 0.6959 - val_loss: 2.4532 - val_acc: 0.5500\n",
      "Epoch 295/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.1292 - acc: 0.6550 - val_loss: 2.4399 - val_acc: 0.5500\n",
      "Epoch 296/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.1144 - acc: 0.7076 - val_loss: 2.4270 - val_acc: 0.5500\n",
      "Epoch 297/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.1044 - acc: 0.6491 - val_loss: 2.4144 - val_acc: 0.5500\n",
      "Epoch 298/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.1046 - acc: 0.6608 - val_loss: 2.4022 - val_acc: 0.5500\n",
      "Epoch 299/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.0749 - acc: 0.6959 - val_loss: 2.3900 - val_acc: 0.5500\n",
      "Epoch 300/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 2.0618 - acc: 0.6608 - val_loss: 2.3778 - val_acc: 0.5500\n",
      "Epoch 301/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.0465 - acc: 0.6959 - val_loss: 2.3657 - val_acc: 0.5500\n",
      "Epoch 302/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.0548 - acc: 0.6725 - val_loss: 2.3537 - val_acc: 0.5500\n",
      "Epoch 303/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.0297 - acc: 0.6491 - val_loss: 2.3417 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.0356 - acc: 0.6784 - val_loss: 2.3295 - val_acc: 0.5500\n",
      "Epoch 305/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 2.0092 - acc: 0.6667 - val_loss: 2.3176 - val_acc: 0.5500\n",
      "Epoch 306/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.0158 - acc: 0.6667 - val_loss: 2.3059 - val_acc: 0.5500\n",
      "Epoch 307/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 2.0037 - acc: 0.6842 - val_loss: 2.2944 - val_acc: 0.5500\n",
      "Epoch 308/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.9571 - acc: 0.6667 - val_loss: 2.2833 - val_acc: 0.5500\n",
      "Epoch 309/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.9754 - acc: 0.6725 - val_loss: 2.2723 - val_acc: 0.5500\n",
      "Epoch 310/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.9578 - acc: 0.6842 - val_loss: 2.2615 - val_acc: 0.5500\n",
      "Epoch 311/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.9509 - acc: 0.6784 - val_loss: 2.2510 - val_acc: 0.5500\n",
      "Epoch 312/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.9254 - acc: 0.6550 - val_loss: 2.2409 - val_acc: 0.5500\n",
      "Epoch 313/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.9143 - acc: 0.7018 - val_loss: 2.2309 - val_acc: 0.5500\n",
      "Epoch 314/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.9148 - acc: 0.6608 - val_loss: 2.2208 - val_acc: 0.5500\n",
      "Epoch 315/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.8601 - acc: 0.7018 - val_loss: 2.2108 - val_acc: 0.5500\n",
      "Epoch 316/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.8609 - acc: 0.6842 - val_loss: 2.2007 - val_acc: 0.5500\n",
      "Epoch 317/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.8837 - acc: 0.6725 - val_loss: 2.1906 - val_acc: 0.5500\n",
      "Epoch 318/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.8541 - acc: 0.6725 - val_loss: 2.1808 - val_acc: 0.5500\n",
      "Epoch 319/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.8392 - acc: 0.6725 - val_loss: 2.1711 - val_acc: 0.5500\n",
      "Epoch 320/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.8355 - acc: 0.6901 - val_loss: 2.1614 - val_acc: 0.5500\n",
      "Epoch 321/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.8532 - acc: 0.6842 - val_loss: 2.1515 - val_acc: 0.5500\n",
      "Epoch 322/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.8255 - acc: 0.6725 - val_loss: 2.1421 - val_acc: 0.5500\n",
      "Epoch 323/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.8143 - acc: 0.6901 - val_loss: 2.1326 - val_acc: 0.5500\n",
      "Epoch 324/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.7861 - acc: 0.6901 - val_loss: 2.1234 - val_acc: 0.5500\n",
      "Epoch 325/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.7937 - acc: 0.7018 - val_loss: 2.1143 - val_acc: 0.5500\n",
      "Epoch 326/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.7997 - acc: 0.6784 - val_loss: 2.1055 - val_acc: 0.5500\n",
      "Epoch 327/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.7689 - acc: 0.6842 - val_loss: 2.0968 - val_acc: 0.5500\n",
      "Epoch 328/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.7661 - acc: 0.6784 - val_loss: 2.0883 - val_acc: 0.5500\n",
      "Epoch 329/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.7671 - acc: 0.6784 - val_loss: 2.0799 - val_acc: 0.5500\n",
      "Epoch 330/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.7360 - acc: 0.6901 - val_loss: 2.0712 - val_acc: 0.5500\n",
      "Epoch 331/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.7281 - acc: 0.7135 - val_loss: 2.0626 - val_acc: 0.5500\n",
      "Epoch 332/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.7201 - acc: 0.6842 - val_loss: 2.0538 - val_acc: 0.5500\n",
      "Epoch 333/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.7311 - acc: 0.6784 - val_loss: 2.0452 - val_acc: 0.5500\n",
      "Epoch 334/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.7204 - acc: 0.7018 - val_loss: 2.0367 - val_acc: 0.5500\n",
      "Epoch 335/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.6986 - acc: 0.7018 - val_loss: 2.0283 - val_acc: 0.5500\n",
      "Epoch 336/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.6878 - acc: 0.6784 - val_loss: 2.0202 - val_acc: 0.5500\n",
      "Epoch 337/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.6868 - acc: 0.7018 - val_loss: 2.0122 - val_acc: 0.5500\n",
      "Epoch 338/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.6695 - acc: 0.6901 - val_loss: 2.0041 - val_acc: 0.5500\n",
      "Epoch 339/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.6732 - acc: 0.6667 - val_loss: 1.9961 - val_acc: 0.5500\n",
      "Epoch 340/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.6664 - acc: 0.6784 - val_loss: 1.9882 - val_acc: 0.5500\n",
      "Epoch 341/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.6647 - acc: 0.6901 - val_loss: 1.9805 - val_acc: 0.5500\n",
      "Epoch 342/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.6454 - acc: 0.6784 - val_loss: 1.9733 - val_acc: 0.5500\n",
      "Epoch 343/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.6065 - acc: 0.7018 - val_loss: 1.9664 - val_acc: 0.5500\n",
      "Epoch 344/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.6553 - acc: 0.6725 - val_loss: 1.9595 - val_acc: 0.5500\n",
      "Epoch 345/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.6066 - acc: 0.6959 - val_loss: 1.9524 - val_acc: 0.5500\n",
      "Epoch 346/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5963 - acc: 0.6901 - val_loss: 1.9456 - val_acc: 0.5500\n",
      "Epoch 347/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.6216 - acc: 0.7076 - val_loss: 1.9388 - val_acc: 0.5500\n",
      "Epoch 348/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5839 - acc: 0.7251 - val_loss: 1.9320 - val_acc: 0.5500\n",
      "Epoch 349/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.6057 - acc: 0.7135 - val_loss: 1.9258 - val_acc: 0.5500\n",
      "Epoch 350/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.5629 - acc: 0.6784 - val_loss: 1.9193 - val_acc: 0.5500\n",
      "Epoch 351/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5935 - acc: 0.6725 - val_loss: 1.9132 - val_acc: 0.5000\n",
      "Epoch 352/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5793 - acc: 0.6842 - val_loss: 1.9072 - val_acc: 0.5000\n",
      "Epoch 353/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5549 - acc: 0.7135 - val_loss: 1.9010 - val_acc: 0.5000\n",
      "Epoch 354/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.5336 - acc: 0.7076 - val_loss: 1.8954 - val_acc: 0.5000\n",
      "Epoch 355/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5379 - acc: 0.6784 - val_loss: 1.8899 - val_acc: 0.5000\n",
      "Epoch 356/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5341 - acc: 0.6842 - val_loss: 1.8842 - val_acc: 0.5000\n",
      "Epoch 357/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5681 - acc: 0.6784 - val_loss: 1.8786 - val_acc: 0.5000\n",
      "Epoch 358/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5443 - acc: 0.6725 - val_loss: 1.8731 - val_acc: 0.5000\n",
      "Epoch 359/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5218 - acc: 0.7018 - val_loss: 1.8678 - val_acc: 0.5000\n",
      "Epoch 360/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5338 - acc: 0.6901 - val_loss: 1.8622 - val_acc: 0.5000\n",
      "Epoch 361/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.4946 - acc: 0.6842 - val_loss: 1.8564 - val_acc: 0.5000\n",
      "Epoch 362/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.4844 - acc: 0.7193 - val_loss: 1.8505 - val_acc: 0.5000\n",
      "Epoch 363/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4756 - acc: 0.7251 - val_loss: 1.8447 - val_acc: 0.5000\n",
      "Epoch 364/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4748 - acc: 0.7193 - val_loss: 1.8387 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4883 - acc: 0.6784 - val_loss: 1.8329 - val_acc: 0.5000\n",
      "Epoch 366/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.4949 - acc: 0.6725 - val_loss: 1.8269 - val_acc: 0.5000\n",
      "Epoch 367/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.5003 - acc: 0.6608 - val_loss: 1.8210 - val_acc: 0.5000\n",
      "Epoch 368/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4429 - acc: 0.7251 - val_loss: 1.8152 - val_acc: 0.5000\n",
      "Epoch 369/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4707 - acc: 0.6550 - val_loss: 1.8099 - val_acc: 0.5000\n",
      "Epoch 370/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.4486 - acc: 0.7076 - val_loss: 1.8048 - val_acc: 0.5000\n",
      "Epoch 371/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4530 - acc: 0.6959 - val_loss: 1.7997 - val_acc: 0.5000\n",
      "Epoch 372/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4369 - acc: 0.6901 - val_loss: 1.7952 - val_acc: 0.5000\n",
      "Epoch 373/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4352 - acc: 0.7251 - val_loss: 1.7908 - val_acc: 0.5000\n",
      "Epoch 374/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4075 - acc: 0.6901 - val_loss: 1.7863 - val_acc: 0.5000\n",
      "Epoch 375/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4177 - acc: 0.6901 - val_loss: 1.7816 - val_acc: 0.5000\n",
      "Epoch 376/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4114 - acc: 0.6901 - val_loss: 1.7768 - val_acc: 0.5000\n",
      "Epoch 377/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.4010 - acc: 0.7018 - val_loss: 1.7717 - val_acc: 0.5500\n",
      "Epoch 378/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.4138 - acc: 0.6784 - val_loss: 1.7664 - val_acc: 0.5500\n",
      "Epoch 379/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.3906 - acc: 0.7018 - val_loss: 1.7615 - val_acc: 0.5500\n",
      "Epoch 380/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3900 - acc: 0.7076 - val_loss: 1.7569 - val_acc: 0.5500\n",
      "Epoch 381/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3979 - acc: 0.6667 - val_loss: 1.7519 - val_acc: 0.5500\n",
      "Epoch 382/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.3717 - acc: 0.6959 - val_loss: 1.7468 - val_acc: 0.5000\n",
      "Epoch 383/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3847 - acc: 0.7018 - val_loss: 1.7421 - val_acc: 0.5000\n",
      "Epoch 384/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3672 - acc: 0.7135 - val_loss: 1.7376 - val_acc: 0.5000\n",
      "Epoch 385/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3888 - acc: 0.6608 - val_loss: 1.7330 - val_acc: 0.5000\n",
      "Epoch 386/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.3708 - acc: 0.7135 - val_loss: 1.7282 - val_acc: 0.5000\n",
      "Epoch 387/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3607 - acc: 0.7193 - val_loss: 1.7235 - val_acc: 0.5000\n",
      "Epoch 388/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3359 - acc: 0.6959 - val_loss: 1.7190 - val_acc: 0.5000\n",
      "Epoch 389/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3669 - acc: 0.6725 - val_loss: 1.7143 - val_acc: 0.5000\n",
      "Epoch 390/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.3237 - acc: 0.6959 - val_loss: 1.7098 - val_acc: 0.5000\n",
      "Epoch 391/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3356 - acc: 0.6959 - val_loss: 1.7056 - val_acc: 0.5000\n",
      "Epoch 392/500\n",
      "171/171 [==============================] - 0s 22us/step - loss: 1.3746 - acc: 0.6784 - val_loss: 1.7016 - val_acc: 0.5000\n",
      "Epoch 393/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.3302 - acc: 0.6784 - val_loss: 1.6979 - val_acc: 0.5000\n",
      "Epoch 394/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.3241 - acc: 0.7018 - val_loss: 1.6942 - val_acc: 0.5000\n",
      "Epoch 395/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3167 - acc: 0.7018 - val_loss: 1.6907 - val_acc: 0.5000\n",
      "Epoch 396/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3195 - acc: 0.7018 - val_loss: 1.6872 - val_acc: 0.5000\n",
      "Epoch 397/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.3154 - acc: 0.6725 - val_loss: 1.6838 - val_acc: 0.5000\n",
      "Epoch 398/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.3240 - acc: 0.6901 - val_loss: 1.6804 - val_acc: 0.5000\n",
      "Epoch 399/500\n",
      "171/171 [==============================] - 0s 28us/step - loss: 1.2797 - acc: 0.7485 - val_loss: 1.6764 - val_acc: 0.5000\n",
      "Epoch 400/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2957 - acc: 0.6959 - val_loss: 1.6721 - val_acc: 0.5000\n",
      "Epoch 401/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.3106 - acc: 0.7076 - val_loss: 1.6681 - val_acc: 0.5000\n",
      "Epoch 402/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2823 - acc: 0.7310 - val_loss: 1.6641 - val_acc: 0.5000\n",
      "Epoch 403/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2878 - acc: 0.6725 - val_loss: 1.6602 - val_acc: 0.5000\n",
      "Epoch 404/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.2729 - acc: 0.7076 - val_loss: 1.6560 - val_acc: 0.5000\n",
      "Epoch 405/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2917 - acc: 0.7135 - val_loss: 1.6514 - val_acc: 0.5000\n",
      "Epoch 406/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2860 - acc: 0.6959 - val_loss: 1.6462 - val_acc: 0.5000\n",
      "Epoch 407/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2802 - acc: 0.7076 - val_loss: 1.6411 - val_acc: 0.5000\n",
      "Epoch 408/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.2643 - acc: 0.7310 - val_loss: 1.6364 - val_acc: 0.5000\n",
      "Epoch 409/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2457 - acc: 0.7251 - val_loss: 1.6322 - val_acc: 0.5000\n",
      "Epoch 410/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.2375 - acc: 0.7135 - val_loss: 1.6277 - val_acc: 0.5000\n",
      "Epoch 411/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.2601 - acc: 0.7076 - val_loss: 1.6233 - val_acc: 0.5000\n",
      "Epoch 412/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2505 - acc: 0.6901 - val_loss: 1.6189 - val_acc: 0.5000\n",
      "Epoch 413/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2509 - acc: 0.7018 - val_loss: 1.6148 - val_acc: 0.5000\n",
      "Epoch 414/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.2165 - acc: 0.7193 - val_loss: 1.6112 - val_acc: 0.5000\n",
      "Epoch 415/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2008 - acc: 0.7135 - val_loss: 1.6079 - val_acc: 0.5000\n",
      "Epoch 416/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2311 - acc: 0.7251 - val_loss: 1.6046 - val_acc: 0.5000\n",
      "Epoch 417/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2426 - acc: 0.6959 - val_loss: 1.6015 - val_acc: 0.5000\n",
      "Epoch 418/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2319 - acc: 0.6959 - val_loss: 1.5984 - val_acc: 0.5000\n",
      "Epoch 419/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 1.2437 - acc: 0.7018 - val_loss: 1.5956 - val_acc: 0.5000\n",
      "Epoch 420/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.2443 - acc: 0.7135 - val_loss: 1.5927 - val_acc: 0.5000\n",
      "Epoch 421/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2253 - acc: 0.6842 - val_loss: 1.5900 - val_acc: 0.5000\n",
      "Epoch 422/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2224 - acc: 0.6842 - val_loss: 1.5873 - val_acc: 0.5000\n",
      "Epoch 423/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.2352 - acc: 0.7135 - val_loss: 1.5849 - val_acc: 0.5000\n",
      "Epoch 424/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.1937 - acc: 0.7251 - val_loss: 1.5828 - val_acc: 0.5000\n",
      "Epoch 425/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2201 - acc: 0.6901 - val_loss: 1.5803 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2176 - acc: 0.6901 - val_loss: 1.5777 - val_acc: 0.5000\n",
      "Epoch 427/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.1958 - acc: 0.7310 - val_loss: 1.5758 - val_acc: 0.5000\n",
      "Epoch 428/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1931 - acc: 0.7193 - val_loss: 1.5738 - val_acc: 0.5000\n",
      "Epoch 429/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2063 - acc: 0.7018 - val_loss: 1.5722 - val_acc: 0.5000\n",
      "Epoch 430/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.2242 - acc: 0.7018 - val_loss: 1.5703 - val_acc: 0.5000\n",
      "Epoch 431/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.1874 - acc: 0.7193 - val_loss: 1.5686 - val_acc: 0.5000\n",
      "Epoch 432/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1837 - acc: 0.6959 - val_loss: 1.5666 - val_acc: 0.5000\n",
      "Epoch 433/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1904 - acc: 0.6901 - val_loss: 1.5638 - val_acc: 0.5000\n",
      "Epoch 434/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 1.1813 - acc: 0.7018 - val_loss: 1.5609 - val_acc: 0.5000\n",
      "Epoch 435/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1826 - acc: 0.7076 - val_loss: 1.5587 - val_acc: 0.5000\n",
      "Epoch 436/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1810 - acc: 0.7251 - val_loss: 1.5568 - val_acc: 0.5000\n",
      "Epoch 437/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1754 - acc: 0.6959 - val_loss: 1.5546 - val_acc: 0.5000\n",
      "Epoch 438/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.1606 - acc: 0.7018 - val_loss: 1.5521 - val_acc: 0.5000\n",
      "Epoch 439/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.1574 - acc: 0.7368 - val_loss: 1.5501 - val_acc: 0.5000\n",
      "Epoch 440/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1596 - acc: 0.6959 - val_loss: 1.5481 - val_acc: 0.5000\n",
      "Epoch 441/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.1624 - acc: 0.6842 - val_loss: 1.5470 - val_acc: 0.5000\n",
      "Epoch 442/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.1624 - acc: 0.6842 - val_loss: 1.5456 - val_acc: 0.5000\n",
      "Epoch 443/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1679 - acc: 0.7018 - val_loss: 1.5439 - val_acc: 0.5000\n",
      "Epoch 444/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.1233 - acc: 0.7251 - val_loss: 1.5415 - val_acc: 0.5000\n",
      "Epoch 445/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 1.1549 - acc: 0.7076 - val_loss: 1.5388 - val_acc: 0.5000\n",
      "Epoch 446/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1613 - acc: 0.7018 - val_loss: 1.5363 - val_acc: 0.5000\n",
      "Epoch 447/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.1624 - acc: 0.6901 - val_loss: 1.5336 - val_acc: 0.5000\n",
      "Epoch 448/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1672 - acc: 0.6667 - val_loss: 1.5314 - val_acc: 0.5000\n",
      "Epoch 449/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.1541 - acc: 0.7076 - val_loss: 1.5295 - val_acc: 0.5000\n",
      "Epoch 450/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1345 - acc: 0.7076 - val_loss: 1.5265 - val_acc: 0.5000\n",
      "Epoch 451/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1365 - acc: 0.6959 - val_loss: 1.5237 - val_acc: 0.5000\n",
      "Epoch 452/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.1194 - acc: 0.7368 - val_loss: 1.5217 - val_acc: 0.5000\n",
      "Epoch 453/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 1.1178 - acc: 0.6901 - val_loss: 1.5196 - val_acc: 0.5000\n",
      "Epoch 454/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.1348 - acc: 0.7076 - val_loss: 1.5169 - val_acc: 0.5000\n",
      "Epoch 455/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.1290 - acc: 0.6901 - val_loss: 1.5146 - val_acc: 0.5000\n",
      "Epoch 456/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.1482 - acc: 0.6784 - val_loss: 1.5122 - val_acc: 0.5000\n",
      "Epoch 457/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1047 - acc: 0.7251 - val_loss: 1.5102 - val_acc: 0.5000\n",
      "Epoch 458/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1253 - acc: 0.6959 - val_loss: 1.5086 - val_acc: 0.5000\n",
      "Epoch 459/500\n",
      "171/171 [==============================] - 0s 29us/step - loss: 1.1388 - acc: 0.6901 - val_loss: 1.5071 - val_acc: 0.5000\n",
      "Epoch 460/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1132 - acc: 0.7544 - val_loss: 1.5052 - val_acc: 0.5000\n",
      "Epoch 461/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1183 - acc: 0.7193 - val_loss: 1.5032 - val_acc: 0.5000\n",
      "Epoch 462/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1036 - acc: 0.7135 - val_loss: 1.5012 - val_acc: 0.5000\n",
      "Epoch 463/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0637 - acc: 0.7368 - val_loss: 1.4988 - val_acc: 0.5000\n",
      "Epoch 464/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.1056 - acc: 0.6842 - val_loss: 1.4966 - val_acc: 0.5000\n",
      "Epoch 465/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.0987 - acc: 0.7193 - val_loss: 1.4948 - val_acc: 0.5000\n",
      "Epoch 466/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0941 - acc: 0.7310 - val_loss: 1.4931 - val_acc: 0.5000\n",
      "Epoch 467/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0621 - acc: 0.7602 - val_loss: 1.4918 - val_acc: 0.5000\n",
      "Epoch 468/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.1068 - acc: 0.7310 - val_loss: 1.4902 - val_acc: 0.5000\n",
      "Epoch 469/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0861 - acc: 0.7310 - val_loss: 1.4880 - val_acc: 0.5000\n",
      "Epoch 470/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0834 - acc: 0.7193 - val_loss: 1.4855 - val_acc: 0.5000\n",
      "Epoch 471/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0836 - acc: 0.7193 - val_loss: 1.4826 - val_acc: 0.5000\n",
      "Epoch 472/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0812 - acc: 0.7485 - val_loss: 1.4799 - val_acc: 0.5000\n",
      "Epoch 473/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0712 - acc: 0.7251 - val_loss: 1.4775 - val_acc: 0.5000\n",
      "Epoch 474/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0778 - acc: 0.7018 - val_loss: 1.4759 - val_acc: 0.5000\n",
      "Epoch 475/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0824 - acc: 0.7076 - val_loss: 1.4747 - val_acc: 0.5000\n",
      "Epoch 476/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.0899 - acc: 0.7368 - val_loss: 1.4736 - val_acc: 0.5000\n",
      "Epoch 477/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0656 - acc: 0.7427 - val_loss: 1.4726 - val_acc: 0.5000\n",
      "Epoch 478/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0766 - acc: 0.7193 - val_loss: 1.4713 - val_acc: 0.5000\n",
      "Epoch 479/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.0600 - acc: 0.7193 - val_loss: 1.4699 - val_acc: 0.5000\n",
      "Epoch 480/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0618 - acc: 0.7135 - val_loss: 1.4685 - val_acc: 0.5000\n",
      "Epoch 481/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 1.0609 - acc: 0.7310 - val_loss: 1.4675 - val_acc: 0.5000\n",
      "Epoch 482/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0987 - acc: 0.7135 - val_loss: 1.4671 - val_acc: 0.5000\n",
      "Epoch 483/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0537 - acc: 0.7368 - val_loss: 1.4659 - val_acc: 0.5000\n",
      "Epoch 484/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0679 - acc: 0.7427 - val_loss: 1.4651 - val_acc: 0.5000\n",
      "Epoch 485/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 1.0630 - acc: 0.7076 - val_loss: 1.4643 - val_acc: 0.5000\n",
      "Epoch 486/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0460 - acc: 0.7427 - val_loss: 1.4632 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.0812 - acc: 0.6842 - val_loss: 1.4620 - val_acc: 0.5000\n",
      "Epoch 488/500\n",
      "171/171 [==============================] - 0s 24us/step - loss: 1.0502 - acc: 0.7310 - val_loss: 1.4605 - val_acc: 0.5000\n",
      "Epoch 489/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0623 - acc: 0.7076 - val_loss: 1.4589 - val_acc: 0.5000\n",
      "Epoch 490/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.0588 - acc: 0.7368 - val_loss: 1.4573 - val_acc: 0.5000\n",
      "Epoch 491/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0393 - acc: 0.7310 - val_loss: 1.4556 - val_acc: 0.5000\n",
      "Epoch 492/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0267 - acc: 0.7135 - val_loss: 1.4539 - val_acc: 0.5000\n",
      "Epoch 493/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0762 - acc: 0.6842 - val_loss: 1.4524 - val_acc: 0.5000\n",
      "Epoch 494/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0602 - acc: 0.7193 - val_loss: 1.4512 - val_acc: 0.5000\n",
      "Epoch 495/500\n",
      "171/171 [==============================] - 0s 17us/step - loss: 1.0548 - acc: 0.6842 - val_loss: 1.4505 - val_acc: 0.5000\n",
      "Epoch 496/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0381 - acc: 0.7251 - val_loss: 1.4499 - val_acc: 0.5000\n",
      "Epoch 497/500\n",
      "171/171 [==============================] - 0s 18us/step - loss: 1.0595 - acc: 0.6784 - val_loss: 1.4489 - val_acc: 0.5000\n",
      "Epoch 498/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0550 - acc: 0.7018 - val_loss: 1.4481 - val_acc: 0.5000\n",
      "Epoch 499/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0254 - acc: 0.7251 - val_loss: 1.4475 - val_acc: 0.5000\n",
      "Epoch 500/500\n",
      "171/171 [==============================] - 0s 23us/step - loss: 1.0433 - acc: 0.7310 - val_loss: 1.4469 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(new_all_feature , train_y, \n",
    "                          validation_split=0.1, \n",
    "                          epochs = 500, batch_size=171,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_history,train,validation):  #,validation\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'],loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_history,'acc','val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_history,'loss','val_loss')  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.read_csv('0527test_data_final_real.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('0625test_data_final_real.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['HOSDAY'] = test['HOSDAY'].map({\"A\": 0, \"B\":1, \"C\":2, \"D\":3 }).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = test.columns[1:]\n",
    "test_target = test.columns[0]\n",
    "test_feature = test[test_feature]\n",
    "test_y = test[test_target]\n",
    "test_y = test_y.values\n",
    "test_y = np_utils.to_categorical(test_y, num_classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaledFeatures  = ( ( test_feature - train_feature.mean(axis=0) ) / train_feature.std(axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out =  model.predict(test_scaledFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48153198, 0.26119316, 0.17927398, 0.07800084],\n",
       "       [0.61822164, 0.22314264, 0.10461243, 0.05402329],\n",
       "       [0.5670426 , 0.28341264, 0.08924884, 0.06029589],\n",
       "       [0.7279155 , 0.17037569, 0.05902144, 0.04268727],\n",
       "       [0.60282683, 0.17014399, 0.1376477 , 0.08938149],\n",
       "       [0.5014187 , 0.2886538 , 0.1429008 , 0.0670267 ],\n",
       "       [0.6616006 , 0.17762658, 0.10200124, 0.05877155],\n",
       "       [0.73070717, 0.09966764, 0.10128769, 0.06833754],\n",
       "       [0.6846141 , 0.11654592, 0.12203293, 0.07680703],\n",
       "       [0.50331026, 0.28003207, 0.1473011 , 0.06935656],\n",
       "       [0.6057134 , 0.17710817, 0.13957708, 0.07760133]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_class =  model.predict_classes(test_scaledFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['HOSDAY'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Species</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Species</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Species  0\n",
       "Actual Species      \n",
       "0                  5\n",
       "1                  6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab( test['HOSDAY'].values, test_out_class, rownames=['Actual Species'], colnames=['Predicted Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3180824518203735, 0.4545454680919647]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = model.evaluate(test_scaledFeatures, test_y, verbose=2)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
